\title{Epileptic Seizure Detection from EEG Signals with Deep Belief Networks}
\author{Tuan Nguyen}
\date{\today}

\documentclass[12pt]{article}

\usepackage{url}

\newcommand{\myvec}[1]{\vec{#1}}

\begin{document}
\maketitle

\section{Domain Background}

\noindent
The domain of interest of this project belongs to physiological data such as electroencephalography (EEG), magnetoencephalography (MEG), electrocardiography (ECG) and the recorded signals from wearable devices. This project focuses on the EEG signals, which capture activities of brain neurons during a period of time. Different kinds of EEG data has been recorded from humans, for instance from those at rest, sleep~\cite{langkvist2012sleep}, during some periods of specific cognitive activity, or from patients with diseases such as Alzheimer's, Parkinson's, depression and epileptic seisures (\cite{andrzejak2001indications} and references thereof).

This project studies the classification problem on an EEG data set recorded from healthy volunteers and patients having epileptic seizures; solutions for this problem could be used to assist with detecting patients with the disease from their brain activity signals. Previous work on this data set focused mainly on extracting hand-crafted features to be used for classification. As examples, Nigam and Graupe \cite{nigam2004neural} extracted two the spike amplitudes and frequency of the signals, feeding them into a neural network for classification; Guler et al.~\cite{guler2005recurrent} applied wavelet transform to the signal to extract features, and classification was performed using neuro-fuzzy system; \cite{kannathal2005entropies} extracted entropy-based features for classification. This project, on the other hand, learns features representing the EEG signals automatically using Deep Belief Networks (DBNs)~\cite{hinton2006reducing}, and then use them for classification.

\section{Problem Statement}
\noindent
This project aims to classify 1-sec long EEG segments into one of the three classes: (1) healthy volunteers, (2) patients with epileptic seizures disease during seizure-free periods, and (3) patients with the disease during active seizure periods. It can be formally defined as follows.

\begin{itemize}
\item \textbf{Input:} training set $X = \langle \myvec{x}_1, \myvec{x}_2, ..., \myvec{x}_N\rangle$ of $N$ samples, where $\myvec{x}_i$ is a vector of $M$ electrical voltage values recorded in one second by an electrode at a specific point and time; target vector $y = \langle y_1, y_2, ..., y_N \rangle$ where $y_i \in \{1, 2, 3\}$ is the type of volunteers which the sample $\myvec{x}_i$ belong to. In the data set~\cite{andrzejak2001indications}, the targets $1, 2, 3$ respectively correspond to sets of volunteers $A + B$, $C + D$ and $E$.
\item \textbf{Output:} a hypothesis $f$ classifying a sample of $M$ electrical voltage values into one of the volunteer classes $\{1, 2, 3\}$.
\end{itemize}

The formation of the training set $X$ and target $y$ is discussed in Section~\ref{sec:data_set}. This project explores the usage of Deep Belief Networks for learning features of the training set $X$ and popular learning models (Decision Trees, K-Kearest Neighbors, Support Vector Machines and Feedforward Multi-layer Neural Networks) for classification (see Section~\ref{sec:solution}). Several metrics are used to evaluate the classifiers, discussed in Section~\ref{sec:metric}.

\section{Data Sets and Inputs}
\label{sec:data_set}
The data set used in this study is provided with the work by Andrzejak et al.~\cite{andrzejak2001indications}, recording brain electrical activity of five sets of human volunteers:
\begin{itemize}
\item Set A: healthy volunteers in relaxed state with eyes open.
\item Set B: healthy volunteers in relaxed state with eyes closed.
\item Set D: epilepsy patients during seizure-free periods; the electrodes were implanted to record brain activity from within the epileptogenic zone.
\item Set C: epilepsy patients during seizure-free periods; the electrodes were implanted from the opposite hemisphere of the brain (compared to those in Set D).
\item Set E: same patients with sets C and D but activity were recorded from all electrodes during active seizures.
\end{itemize}

For each set of volunteers above, the data set contains 100 single-channel EEG segments of 23.6-sec duration. For this project each of these segments is divided into smaller segments of one second durations, which are considered stationary for EEG data~\cite{nigam2004neural}. These one second durations together define the training set $X$ in the problem statement, and the three sets of volunteers $A + B$, $C + D$ and $E$ define the target vector $y$ in the problem statement above.

\section{Solution Statements}
\label{sec:solution}

This project aims to propose an instance of DBNs that can learn to extract features of the training set $X$ for the purpose of classifying new sample of EEG segments. The network consists of a sequence of stacked Boltzman machines restricted to have symmetric connections between the input layer and the only output layer~\cite{hinton2006training}. This restriction enables individual Boltzman machines and the entire network to be trained in the following fashion:
\begin{itemize}
\item \textit{Pretraining}: the Boltzman machines in the stack are trained sequentially one at a time to minimize the difference between the input and output (or its reconstructed values); the learned feature activations of one RBM becomes the input of the one right above (the first machine of the stack has the raw training EEG segments as inputs).
\item \textit{Fine-tunig}: the stacked of restricted Boltzman machines are unrolled to form separate the two encoder and decoder parts; back-propagation is then used to fine tune the network, starting from the weights obtained during the pretrainning period.
\end{itemize}

After the feature learning phase above, the output of the encoder of the network is considered the features representing the training set $X$. They are then used as input features of popular classification algorithms. This work considers the following classifiers: Decision Trees, K-Kearest Neighbors, Support Vector Machines and Feedforward Multi-layer Neural Networks. The hypothesis here is that the features learned automatically using DBNs, together with one of these classifiers, provides comparable performance compared to the previous work (see Section~\ref{sec:benchmark}).

\section{Benchmark Model}
\label{sec:benchmark}
There were several work that aimed to detect seizure patients from the EEG signals in this data set using different hand-chosen features (c.f.~\cite{nigam2004neural}, \cite{kabir2016epileptic}) with excellent accuracy performance. None of them, however, attempted to recognize all five classes of EEG signals from different group of volunteers. On a different data set, Wulsin et al.~\cite{wulsin2011modeling} learned features of second-long segments of EEG signals using DBNs and classified them into ``clinically significant'' EEG classes. Unfortunately, the results from these work cannot be used to compare directly with that of this project. This project, however, aims to compare different combination of feature extraction mechanisms and classification algorithms on the data set~\cite{andrzejak2001indications}, which is an interesting problem by itself.

\section{Evaluation Metrics}
\label{sec:metric}
The quality of the returned hypothesis is evaluated with an independent test set, created by $20\%$ of the given data set. The following measures are used to evaluate the performance of different classifiers:
\begin{itemize}
\item Sensitivity (or recall): the number of positive 
\end{itemize}


\section{Project Design}

\subsection{Step 1: Data Preprocessing}

Use the data from UCI Seizure~\cite{UCISeizure}

Split into train-test (80/20)

Normalize the inputs in the training set, each input vector contains value from [0,1] (Sigmoid unit will be used)

\subsection{Step 2: Design and training individual restricted Boltzman machines}

Design choices to make:
\begin{itemize}
\item Type of visible and hidden units: sigmoid
\item Configuration of machines: 
\end{itemize}

\bibliographystyle{abbrv}
\bibliography{proposal}

\end{document}
